{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here consider the problem of logistic loss.\n",
    "\n",
    "## Model Specification\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = g\\left( \\mathbf{X}\\mathbf{B}^\\top + \\mathbf{Z}\\mathbf{\\Gamma}^\\top \\right),\n",
    "$$\n",
    "where $g$ is the logistic loss function.\n",
    "\n",
    "## Joint Maximum Likelihood Estimation\n",
    "\n",
    "The negative log likelihood is,\n",
    "\n",
    "$$\n",
    "l = \\sum_{i,j}\\left[\\log\\left(1+e^{P_{ij}}\\right) - Y_{ij}P_{ij}\\right],\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P_{ij} &= \\mathbf{X}_{i,:}\\mathbf{B}_{j,:}^\\top + \\mathbf{Z}_{i,:}\\mathbf{\\Gamma}_{j,:}^\\top\\\\\n",
    "&= \\sum_{k=1}^p X_{ik}B_{jk} + \\sum_{l=1}^KZ_{il}\\Gamma_{jl}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Alternating Minimization\n",
    "\n",
    "For the first step, consider $\\mathbf{Z}$ is known, then this is a Multivariate logistic regression. Since the model assumes conditional independence, we can do it column-wise using sklearn package.\n",
    "\n",
    "For the second step, consider $\\mathbf{B}$ and $\\mathbf{\\Gamma}$ is known, then, \n",
    "$$\n",
    "\\frac{\\partial l}{\\partial Z_{il}} = \\sum_{j=1}^q\\frac{\\partial l}{\\partial P_{ij}}\\frac{\\partial P_{ij}}{Z_{il}} = \\sum_{j=1}^p\\frac{e^{P_{ij}}}{1+e^{P_{ij}}}\\Gamma_{jl} = 0.\n",
    "$$\n",
    "\n",
    "There is no explicit solution but is a convex optimization problem. Even though Newton-step is preferred, I will use CVXPY to solve this convex optimization problem. Or scipy.optimize using minimize function and default setting should be good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JML(Y, X, K, esp = 1e-3):\n",
    "    q = Y.shape[1]\n",
    "    p = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # Initialize Z\n",
    "    Z0 = np.random.randn(n, K)\n",
    "    Gamma0 = np.random.randn(q, K)\n",
    "    B0 = np.random.randn(q, p)\n",
    "\n",
    "    def iter_z_fix(Z, B_old, Gamma_old):\n",
    "        def obj_fn(BGamma, shape):\n",
    "            BGamma = BGamma.reshape(shape)\n",
    "            B = BGamma[:,:p]\n",
    "            Gamma = BGamma[:,p:]\n",
    "            P = X @ B.T + Z @ Gamma.T\n",
    "            return np.sum(softplus(P)-Y * P)\n",
    "\n",
    "        shape = (q, p + K)\n",
    "        BGamma0 = np.hstack([B_old, Gamma_old])\n",
    "        BGamma0 = BGamma0.flatten()\n",
    "        opt_res = minimize(obj_fn, BGamma0, args=(shape,), method='Newton-CG')\n",
    "        \n",
    "        BGamma = opt_res.x.reshape(shape)\n",
    "        B = BGamma[:,:p]\n",
    "        Gamma = BGamma[:,p:]\n",
    "        return B, Gamma\n",
    "    \n",
    "    def iter_BG_fix(B, Gamma, Z_old):\n",
    "        def obj_fn(Z, shape):\n",
    "            Z = Z.reshape(shape)\n",
    "            P = X @ B.T + Z @ Gamma.T\n",
    "            return np.sum(softplus(P)-Y * P)\n",
    "        \n",
    "        shape = Z_old.shape\n",
    "        Z_old = Z_old.flatten()\n",
    "        # opt_res = minimize(obj_fn, Z_old, args=(shape,), options={'maxiter':int(1e7)})\n",
    "        opt_res = minimize(obj_fn, Z_old, args=(shape,), method='Newton-CG')\n",
    "        return opt_res.x.reshape(shape)\n",
    "        # if opt_res.success:\n",
    "        #     return opt_res.x.reshape(shape)\n",
    "        # else:\n",
    "        #     raise AssertionError(\"Not Reach Minimum\")\n",
    "    \n",
    "    ## Stop Here. There should be a while loop to connect everything together\n",
    "    # give me while loop of iter_z_fix and iter_BG_fix\n",
    "    Z = Z0\n",
    "    B, Gamma = iter_z_fix(Z0, B0, Gamma0)\n",
    "    Z_new = iter_BG_fix(B, Gamma, Z)\n",
    "    err = scipy.linalg.norm(Z_new - Z)\n",
    "    iter = 0\n",
    "    while err > esp:\n",
    "        Z = Z_new\n",
    "        B_new, Gamma_new = iter_z_fix(Z, B, Gamma)\n",
    "        Z_new = iter_BG_fix(B_new, Gamma_new, Z)\n",
    "        err = np.max([scipy.linalg.norm(Z_new - Z), scipy.linalg.norm(B_new - B), scipy.linalg.norm(Gamma_new - Gamma)])\n",
    "        B = B_new\n",
    "        Gamma = Gamma_new\n",
    "        iter += 1\n",
    "\n",
    "    return B, Z_new, Gamma, iter\n",
    "\n",
    "def rotate_sparse(X, B, Z, Gamma):\n",
    "    n = Z.shape[0]\n",
    "    q = B.shape[0]\n",
    "    p = B.shape[1]\n",
    "    K = Gamma.shape[1]\n",
    "    X_cov = X[:,1:]\n",
    "\n",
    "    def obj_fn(Ac):\n",
    "        return cp.abs(B[1:,:] - Ac.T @ Gamma)\n",
    "    \n",
    "    Ac0 = cp.Variable((q-1, K))\n",
    "    prob = cp.Problem(cp.Minimize(obj_fn(Ac0)))\n",
    "    prob.solve()\n",
    "    Ac = Ac0.value\n",
    "    a0 = -np.mean(X_cov @ Ac.T + Z, axis=0)\n",
    "    A = np.concat([a0.reshape(1, K), Ac], axis=0)\n",
    "\n",
    "    B_new = B - Gamma @ A\n",
    "    Z_mid = Z + X @ A.T\n",
    "\n",
    "    GG_half = scipy.linalg.fractional_matrix_power(Gamma.T @ Gamma, 0.5)\n",
    "    G_full = GG_half @ Z_mid.T @ Z_mid @ GG_half /n/q\n",
    "    d, V = np.linalg.eigh(G_full)\n",
    "    D = np.diag(d**(-1/4))\n",
    "    G = GG_half @ V @ D / np.sqrt(q)\n",
    "\n",
    "    Gamma_new = Gamma @ scipy.linalg.inv(G_full.T)\n",
    "    Z_new = Z_mid @ G\n",
    "\n",
    "    return B_new, Z_new, Gamma_new\n",
    "\n",
    "def rotate_ortho(X, B, Z, Gamma):\n",
    "    n = Z.shape[0]\n",
    "    q = B.shape[0]\n",
    "    p = B.shape[1]\n",
    "    K = Gamma.shape[1]\n",
    "\n",
    "    A = - Z.T @ X @ scipy.linalg.inv(X.T @ X)\n",
    "\n",
    "    B_new = B - Gamma @ A\n",
    "    Z_mid = Z + X @ A.T\n",
    "\n",
    "    GG_half = scipy.linalg.fractional_matrix_power(Gamma.T @ Gamma, 0.5)\n",
    "    G_full = GG_half @ Z_mid.T @ Z_mid @ GG_half /n/q\n",
    "    d, V = np.linalg.eigh(G_full)\n",
    "    D = np.diag(d**(-1/4))\n",
    "    G = GG_half @ V @ D / np.sqrt(q)\n",
    "\n",
    "    Gamma_new = Gamma @ scipy.linalg.inv(G_full.T)\n",
    "    Z_new = Z_mid @ G\n",
    "\n",
    "    return B_new, Z_new, Gamma_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(Y, X, lam):\n",
    "    n = Y.shape[0]\n",
    "    q = Y.shape[1]\n",
    "    p = X.shape[1]\n",
    "\n",
    "    def obj_fn(B, L):\n",
    "        P = X @ B.T + L\n",
    "        return cp.sum(cp.logistic(P)-cp.multiply(Y, P)) + lam * cp.norm(L, \"nuc\")\n",
    "\n",
    "    def constr(X, L):\n",
    "        return X.T @ L == 0\n",
    "\n",
    "    B0 = cp.Variable((q, p))\n",
    "    L0 = cp.Variable((n, q))\n",
    "    obj = cp.Minimize(obj_fn(B0, L0))\n",
    "    constraints = [constr(X, L0)]\n",
    "    prob = cp.Problem(obj, constraints)\n",
    "    prob.solve()\n",
    "    \n",
    "    return prob.status, B0.value, L0.value\n",
    "\n",
    "def SVD_est(L, K):\n",
    "    n = L.shape[0]\n",
    "    q = L.shape[1]\n",
    "\n",
    "    U, S, Vt = scipy.sparse.linalg.svds(L, K)\n",
    "    Pi = (n/q) ** (1/4) * U @ np.diag(S ** (1/2))\n",
    "    Gamma = (q/n) ** (1/4) * Vt.T @ np.diag(S ** (1/2))\n",
    "    \n",
    "    return Pi, Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "i, j = np.ogrid[:10, :10]\n",
    "diff = np.abs(i - j)\n",
    "matrix = 0.2 ** diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "## make L larger through making Gamma larger rather than simply rand n\n",
    "## give some sturcture to it\n",
    "\n",
    "n = 100\n",
    "p = 5\n",
    "q = 50\n",
    "K = 2\n",
    "np.random.seed(1)\n",
    "\n",
    "X = np.random.randn(n, p)\n",
    "# B = np.random.randn(q, p)\n",
    "B_true = np.random.uniform(low=0.3, high=0.7, size=(q, p))\n",
    "X_ortho = scipy.linalg.null_space(X.T)\n",
    "Pi0 = X_ortho[:,:K] * n\n",
    "Gamma0 = np.random.uniform(low=0.5, high=1.5, size=(q, K))\n",
    "L = Pi0 @ Gamma0.T\n",
    "U, S, Vt = scipy.sparse.linalg.svds(L, K)\n",
    "Pi_true = (n/q) ** (1/4) * U @ np.diag(S ** (1/2))\n",
    "Gamma_true = (q/n) ** (1/4) * Vt.T @ np.diag(S ** (1/2))\n",
    "Y0 = X @ B_true.T + L\n",
    "Y = np.random.binomial(1, expit(Y0))\n",
    "# Y = Y0 + np.random.randn(n, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(354196.89320100413)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obj_fn(B, L, lam):\n",
    "    P = X @ B.T + L\n",
    "    return cp.sum((Y - P)**2) + lam * cp.norm(L, \"nuc\")\n",
    "\n",
    "def constr(X, L):\n",
    "    return X.T @ L == 0\n",
    "\n",
    "lam = np.sqrt((n+q)*np.log(n))\n",
    "B0 = cp.Variable((q, p))\n",
    "L0 = cp.Variable((n, q))\n",
    "obj = cp.Minimize(obj_fn(B0, L0, lam))\n",
    "constraints = [constr(X, L0)]\n",
    "prob = cp.Problem(obj, constraints)\n",
    "prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = np.sqrt((n+q)*np.log(np.max([n,q])))\n",
    "is_denoise, B_hat, L_hat = denoise(Y, X, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi_hat, Gamma_hat = SVD_est(L_hat, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.702986003545672\n",
      "1.0000000014478054\n",
      "0.9999885349290456\n",
      "1.0001011901482266\n"
     ]
    }
   ],
   "source": [
    "print(scipy.linalg.norm(B_hat - B) / scipy.linalg.norm(B))\n",
    "print(scipy.linalg.norm(L_hat - L) / scipy.linalg.norm(L))\n",
    "print(scipy.linalg.norm(Pi_hat - Pi) / scipy.linalg.norm(Pi))\n",
    "print(scipy.linalg.norm(Gamma_hat - Gamma) / scipy.linalg.norm(Gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_err = B_hat - B\n",
    "L_err = L_hat - L\n",
    "Pi_err = Pi_hat - Pi\n",
    "Gamma_err = Gamma_hat - Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLARABEL', 'ECOS', 'ECOS_BB', 'OSQP', 'SCIPY', 'SCS']\n"
     ]
    }
   ],
   "source": [
    "print(cp.installed_solvers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(200, 100)\n",
    "B = np.random.randn(100, 100)\n",
    "Z = np.random.randn(200, 3)\n",
    "Gamma = np.random.randn(100, 3)\n",
    "Y = np.exp(X @ B.T + Z @ Gamma.T) / (1 + np.exp(X @ B.T + Z @ Gamma.T))\n",
    "Y = np.random.binomial(1, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m B_hat, Z_hat, Gamma_hat, niter = \u001b[43mJML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mJML\u001b[39m\u001b[34m(Y, X, K, esp)\u001b[39m\n\u001b[32m     53\u001b[39m Z = Z_new\n\u001b[32m     54\u001b[39m B_new, Gamma_new = iter_z_fix(Z, B, Gamma)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m Z_new = \u001b[43miter_BG_fix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGamma_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m err = np.max([scipy.linalg.norm(Z_new - Z), scipy.linalg.norm(B_new - B), scipy.linalg.norm(Gamma_new - Gamma)])\n\u001b[32m     57\u001b[39m B = B_new\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mJML.<locals>.iter_BG_fix\u001b[39m\u001b[34m(B, Gamma, Z_old)\u001b[39m\n\u001b[32m     36\u001b[39m Z_old = Z_old.flatten()\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# opt_res = minimize(obj_fn, Z_old, args=(shape,), options={'maxiter':int(1e7)})\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m opt_res = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m opt_res.x.reshape(shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_minimize.py:738\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    735\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    736\u001b[39m                              **options)\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    741\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    742\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    433\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    434\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    439\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    440\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    443\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    444\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:345\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    343\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:307\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:48\u001b[39m, in \u001b[36m_wrapper_grad.<locals>.wrapped1\u001b[39m\u001b[34m(x, f0)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped1\u001b[39m(x, f0=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     47\u001b[39m     ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinite_diff_options\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:523\u001b[39m, in \u001b[36mapprox_derivative\u001b[39m\u001b[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[39m\n\u001b[32m    520\u001b[39m     use_one_sided = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:596\u001b[39m, in \u001b[36m_dense_difference\u001b[39m\u001b[34m(fun, x0, f0, h, use_one_sided, method)\u001b[39m\n\u001b[32m    594\u001b[39m     x1[i] += h[i]\n\u001b[32m    595\u001b[39m     dx = x1[i] - x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     df = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m - f0\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33m3-point\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[32m    598\u001b[39m     x1[i] += h[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:474\u001b[39m, in \u001b[36mapprox_derivative.<locals>.fun_wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xp.isdtype(x.dtype, \u001b[33m\"\u001b[39m\u001b[33mreal floating\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    472\u001b[39m     x = xp.astype(x, x0.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m f = np.atleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`fun` return value has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mmore than 1 dimension.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[39m, in \u001b[36m_wrapper_fun.<locals>.wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     17\u001b[39m ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mJML.<locals>.iter_BG_fix.<locals>.obj_fn\u001b[39m\u001b[34m(Z, shape)\u001b[39m\n\u001b[32m     31\u001b[39m Z = Z.reshape(shape)\n\u001b[32m     32\u001b[39m P = X @ B.T + Z @ Gamma.T\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.sum(\u001b[43msoftplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m-Y * P)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/scipy/special/_basic.py:3579\u001b[39m, in \u001b[36msoftplus\u001b[39m\u001b[34m(x, **kwargs)\u001b[39m\n\u001b[32m   3549\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msoftplus\u001b[39m(x, **kwargs):\n\u001b[32m   3550\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3551\u001b[39m \u001b[33;03m    Compute the softplus function element-wise.\u001b[39;00m\n\u001b[32m   3552\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3577\u001b[39m \u001b[33;03m    array([0.31326169, 0.69314718, 1.31326169])\u001b[39;00m\n\u001b[32m   3578\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3579\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogaddexp\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "B_hat, Z_hat, Gamma_hat, niter = JML(Y, X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Y.shape[1]\n",
    "p = X.shape[1]\n",
    "n = X.shape[0]\n",
    "\n",
    "# Initialize Z\n",
    "Z0 = np.random.randn(n, K)\n",
    "Gamma0 = np.random.randn(q, K)\n",
    "B0 = np.random.randn(q, p)\n",
    "\n",
    "like_lst = []\n",
    "err_b = []\n",
    "\n",
    "def iter_z_fix(Z, B_old, Gamma_old):\n",
    "    # def obj_fn(BGamma, shape):\n",
    "    #     BGamma = BGamma.reshape(shape)\n",
    "    #     B = BGamma[:,:p]\n",
    "    #     Gamma = BGamma[:,p:]\n",
    "    #     P = X @ B.T + Z @ Gamma.T\n",
    "    #     return np.sum(softplus(P)-Y * P)\n",
    "    def obj_fn(BGamma, shape):\n",
    "        BGamma = BGamma.reshape(shape)\n",
    "        B = BGamma[:,:p]\n",
    "        Gamma = BGamma[:,p:]\n",
    "        P = X @ B.T + Z @ Gamma.T\n",
    "        loss = np.sum(softplus(P)-Y * P)\n",
    "        B_grad = X.T @ (expit(P) - Y)\n",
    "        Gamma_grad = Z.T @ (expit(P) - Y)\n",
    "        grad = np.vstack([B_grad, Gamma_grad]).T\n",
    "        return (loss, grad.flatten())\n",
    "\n",
    "    shape = (q, p + K)\n",
    "    BGamma0 = np.hstack([B_old, Gamma_old])\n",
    "    BGamma0 = BGamma0.flatten()\n",
    "    opt_res = minimize(obj_fn, BGamma0, args=(shape,), method='L-BFGS-B', jac=True)\n",
    "\n",
    "    BGamma = opt_res.x.reshape(shape)\n",
    "    B = BGamma[:,:p]\n",
    "    Gamma = BGamma[:,p:]\n",
    "    return B, Gamma\n",
    "    \n",
    "def iter_BG_fix(B, Gamma, Z_old):\n",
    "    def obj_fn(Z, shape):\n",
    "        Z = Z.reshape(shape)\n",
    "        P = X @ B.T + Z @ Gamma.T\n",
    "        loss = np.sum(softplus(P)-Y * P)\n",
    "        # grad = (Gamma.T @ (expit(P) - Y).T).flatten()\n",
    "        grad = (Gamma.T @ (expit(P) - Y).T).T\n",
    "        return (loss, grad.flatten())\n",
    "        # return np.sum(softplus(P)-Y * P)\n",
    "    \n",
    "    shape = Z_old.shape\n",
    "    Z_old = Z_old.flatten()\n",
    "    # opt_res = minimize(obj_fn, Z_old, args=(shape,), options={'maxiter':int(1e7)})\n",
    "    opt_res = minimize(obj_fn, Z_old, args=(shape,), method='L-BFGS-B', jac=True)\n",
    "    return opt_res.x.reshape(shape)\n",
    "        # if opt_res.success:\n",
    "        #     return opt_res.x.reshape(shape)\n",
    "        # else:\n",
    "        #     raise AssertionError(\"Not Reach Minimum\")\n",
    "    \n",
    "    ## Stop Here. There should be a while loop to connect everything together\n",
    "    # give me while loop of iter_z_fix and iter_BG_fix\n",
    "Z = Z0\n",
    "B, Gamma = iter_z_fix(Z0, B0, Gamma0)\n",
    "Z_new = iter_BG_fix(B, Gamma, Z)\n",
    "err = np.max([scipy.linalg.norm(Z_new - Z), scipy.linalg.norm(B-B0), scipy.linalg.norm(Gamma-Gamma0)])\n",
    "iter = 0\n",
    "while (err > 1e-3) & (iter < 100):\n",
    "    Z = Z_new\n",
    "    B_new, Gamma_new = iter_z_fix(Z, B, Gamma)\n",
    "    Z_new = iter_BG_fix(B_new, Gamma_new, Z)\n",
    "    err = np.max([scipy.linalg.norm(Z_new - Z), scipy.linalg.norm(B_new - B), scipy.linalg.norm(Gamma_new - Gamma)])\n",
    "    err_b.append(np.linalg.norm(B_new - B))\n",
    "    B = B_new\n",
    "    Gamma = Gamma_new\n",
    "    iter += 1\n",
    "    like_lst.append(np.sum(softplus(X @ B.T + Z @ Gamma.T) - Y * (X @ B.T + Z @ Gamma.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.linalg.norm(Gamma_new - Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_orth, Z_orth, Gamma_orth = rotate_ortho(X, B, Z, Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12593.182378450827\n",
      "833.9439072754107\n",
      "29.060436595295226\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "\n",
    "\n",
    "print(scipy.linalg.norm(B_orth - B_true))\n",
    "print(scipy.linalg.norm(Z_orth - Pi_true))\n",
    "print(scipy.linalg.norm(Gamma_orth - Gamma_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.831209257218706\n",
      "41.097182231067826\n",
      "29.0633700522935\n"
     ]
    }
   ],
   "source": [
    "print(scipy.linalg.norm(B_hat - B_true))\n",
    "print(scipy.linalg.norm(Pi_hat - Pi_true))\n",
    "print(scipy.linalg.norm(Gamma_hat - Gamma_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "p = 10\n",
    "K = 3\n",
    "\n",
    "X = np.random.randn(n, K)\n",
    "Beta = np.random.randn(K, p)\n",
    "Y = X @ Beta + np.random.randn(n,p)\n",
    "lam = np.sqrt((n+p) * np.log(np.max((n,p))))\n",
    "\n",
    "Beta0 = cp.Variable((K, p))\n",
    "Gamma0 = cp.Variable((n, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1926.0045456886132)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = cp.Minimize(obj_fn(Y,X,Gamma0,Beta0,lam))\n",
    "constraint = constr(X,Gamma0)\n",
    "prob = cp.Problem(obj, constraint)\n",
    "prob.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_sparse(X, B, Z, Gamma):\n",
    "    n = Z.shape[0]\n",
    "    q = B.shape[0]\n",
    "    p = B.shape[1]\n",
    "    K = Gamma.shape[1]\n",
    "    X_cov = X[:,1:]\n",
    "\n",
    "    def obj_fn(Ac):\n",
    "        return cp.sum(cp.abs(B[:,1:] - Gamma @ Ac))\n",
    "    \n",
    "    # Ac0 = cp.Variable((p-1, K))\n",
    "    Ac0 = cp.Variable((K, p-1))\n",
    "    prob = cp.Problem(cp.Minimize(obj_fn(Ac0)))\n",
    "    prob.solve()\n",
    "    Ac = Ac0.value\n",
    "    a0 = -np.mean(X_cov @ Ac.T + Z, axis=0)\n",
    "    A = np.concat([a0.reshape(K, 1), Ac], axis=1)\n",
    "\n",
    "    B_new = B - Gamma @ A\n",
    "    Z_mid = Z + X @ A.T\n",
    "\n",
    "    GG_half = scipy.linalg.fractional_matrix_power(Gamma.T @ Gamma, 0.5)\n",
    "    G_full = GG_half @ Z_mid.T @ Z_mid @ GG_half /n/q\n",
    "    d, V = np.linalg.eigh(G_full)\n",
    "    D = np.diag(d**(-1/4))\n",
    "    G = GG_half @ V @ D / np.sqrt(q)\n",
    "\n",
    "    Gamma_new = Gamma @ scipy.linalg.inv(G_full.T)\n",
    "    Z_new = Z_mid @ G\n",
    "\n",
    "    return B_new, Z_new, Gamma_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, Z, Gamma = rotate_sparse(X, B_true, Pi_true, Gamma_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import gen_data_sparse\n",
    "\n",
    "n = 200\n",
    "p = 10\n",
    "K = 2\n",
    "q = 100\n",
    "Y, X, B, Pi, Gamma = gen_data_sparse(n, q, p, K, tau=0.5, rho=0.5, seed=1, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (2356776484.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mrv = np.random.uniform(low=0.3, high=0.7, q/K)\u001b[39m\n                                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rv = np.random.uniform(low=0.3, high=0.7, q/K)\n",
    "print(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Process SpawnProcess-214:\n",
      "Process SpawnProcess-215:\n",
      "Process SpawnProcess-216:\n",
      "Process SpawnProcess-213:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_item' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_item' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "AttributeError: Can't get attribute 'process_item' on <module '__main__' (built-in)>\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_item' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenProcessPool\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# with Pool(processes=4) as pool:\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#     results = list(tqdm(pool.imap_unordered(process_item, data), total=len(data)))\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers=\u001b[32m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/process.py:597\u001b[39m, in \u001b[36m_chain_from_iterable_of_lists\u001b[39m\u001b[34m(iterable)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[32m    592\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[32m    594\u001b[39m \u001b[33;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[33;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[32m    596\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/torchbase/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mBrokenProcessPool\u001b[39m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def process_item(x):\n",
    "    return x * x  # Example function\n",
    "\n",
    "data = list(range(100))\n",
    "# with Pool(processes=4) as pool:\n",
    "#     results = list(tqdm(pool.imap_unordered(process_item, data), total=len(data)))\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    results = list(tqdm(executor.map(process_item, data), total=len(data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
